{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "import time\n",
    "import base64\n",
    "import os\n",
    "from openai import OpenAI \n",
    "\n",
    "from IPython.display import Image, display, Audio, Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL=\"gpt-4o\"\n",
    "# MODEL=\"gpt-4-turbo\"\n",
    "openai_api_key = \"sk-proj-vq7xTCAdU9d2V0HKp55jT3BlbkFJBTOBsGNVO9ykIuxH5ZrJ\"\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Grounding dino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from typing import Dict, List, Union\n",
    "import numpy as np\n",
    "from dds_cloudapi_sdk import (\n",
    "    DetectionTask,\n",
    "    Client,\n",
    "    Config,\n",
    "    TextPrompt,\n",
    "    DetectionModel,\n",
    "    DetectionTarget,\n",
    ")\n",
    "from PIL import Image\n",
    "import concurrent.futures\n",
    "\n",
    "class GroundingDINOAPIWrapper:\n",
    "    \"\"\"API wrapper for Grounding DINO 1.5\n",
    "\n",
    "    Args:\n",
    "        token (str): The token for Grounding DINO 1.5 API. We are now opening free API access to Grounding DINO 1.5. For\n",
    "            educators, students, and researchers, we offer an API with extensive usage times to\n",
    "            support your educational and research endeavors. You can get free API token at here:\n",
    "            https://deepdataspace.com/request_api\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, token: str):\n",
    "        self.client = Client(Config(token=token))\n",
    "\n",
    "    def inference(self, prompt: Dict, return_mask:bool=False):\n",
    "        \"\"\"Main inference function of Grounding DINO 1.5. We take batch as input and\n",
    "        each image is a dict. N. We do not support batch inference for now.\n",
    "\n",
    "        Args:\n",
    "            prompts (dict): Annotations with the following keys:\n",
    "                - \"image\" (str): Path to image. E.g. \"test1.jpg\",\n",
    "                - \"prompt\" (str): Text prompt sepearted by '.' E.g. 'cate1 . cate2 . cate3'\n",
    "            return_mask (bool): Whether to return mask. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            (Dict): Detection results in dict format with keys::\n",
    "                - \"scores\": (List[float]): A list of scores for each object in the batch\n",
    "                - \"labels\": (List[int]): A list of labels for each object in the batch\n",
    "                - \"boxes\": (List[List[int]]): A list of boxes for each object in the batch,\n",
    "                     in format [xmin, ymin, xmax, ymax]\n",
    "                - \"masks\": (List[np.ndarray]): A list of segmentations for each object in the batch\n",
    "        \"\"\"\n",
    "        # construct input prompts\n",
    "        image=self.get_image_url(prompt[\"image\"]),\n",
    "        task=DetectionTask(\n",
    "            image_url=image[0],\n",
    "            prompts=[TextPrompt(text=prompt['prompt'])],\n",
    "            targets=[DetectionTarget.Mask, DetectionTarget.BBox] if return_mask else [DetectionTarget.BBox],\n",
    "            model=DetectionModel.GDino1_5_Pro,\n",
    "        )\n",
    "        self.client.run_task(task)\n",
    "        result = task.result\n",
    "        return self.postprocess(result, task, return_mask)\n",
    "\n",
    "\n",
    "    def postprocess(self, result, task, return_mask):\n",
    "        \"\"\"Postprocess the result from the API call\n",
    "\n",
    "        Args:\n",
    "            result (TaskResult): Task result with the following keys:\n",
    "                - objects (List[DetectionObject]): Each DetectionObject has the following keys:\n",
    "                    - bbox (List[float]): Box in xyxy format\n",
    "                    - category (str): Detection category\n",
    "                    - score (float): Detection score\n",
    "                    - mask (DetectionObjectMask): Use mask.counts to parse RLE mask \n",
    "            task (DetectionTask): The task object\n",
    "            return_mask (bool): Whether to return mask\n",
    "\n",
    "        Returns:\n",
    "            (Dict): Return dict in format:\n",
    "                {\n",
    "                    \"scores\": (List[float]): A list of scores for each object\n",
    "                    \"categorys\": (List[str]): A list of categorys for each object\n",
    "                    \"boxes\": (List[List[int]]): A list of boxes for each object\n",
    "                    \"masks\": (List[PIL.Image]): A list of masks in the format of PIL.Image\n",
    "                }\n",
    "        \"\"\"\n",
    "        def process_object_with_mask(object):\n",
    "            box = object.bbox\n",
    "            score = object.score\n",
    "            category = object.category\n",
    "            mask = task.rle2rgba(object.mask)\n",
    "            return box, score, category, mask\n",
    "        \n",
    "        def process_object_without_mask(object):\n",
    "            box = object.bbox\n",
    "            score = object.score\n",
    "            category = object.category\n",
    "            mask = None\n",
    "            return box, score, category, mask\n",
    "        \n",
    "        boxes, scores, categorys, masks = [], [], [], []\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            if return_mask:\n",
    "                process_object = process_object_with_mask\n",
    "            else:\n",
    "                process_object = process_object_without_mask\n",
    "            futures = [executor.submit(process_object, obj) for obj in result.objects]\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                box, score, category, mask = future.result()\n",
    "                boxes.append(box)\n",
    "                scores.append(score)\n",
    "                categorys.append(category)\n",
    "                if mask is not None:\n",
    "                    masks.append(mask)\n",
    "\n",
    "        return dict(boxes=boxes, categorys=categorys, scores=scores, masks=masks)\n",
    "\n",
    "    def get_image_url(self, image: Union[str, np.ndarray]):\n",
    "        \"\"\"Upload Image to server and return the url\n",
    "\n",
    "        Args:\n",
    "            image (Union[str, np.ndarray]): The image to upload. Can be a file path or np.ndarray.\n",
    "                If it is a np.ndarray, it will be saved to a temporary file.\n",
    "\n",
    "        Returns:\n",
    "            str: The url of the image\n",
    "        \"\"\"\n",
    "        if isinstance(image, str):\n",
    "            url = self.client.upload_file(image)\n",
    "        else:\n",
    "            with tempfile.NamedTemporaryFile(delete=True, suffix=\".png\") as tmp_file:\n",
    "                # image is in numpy format, convert to PIL Image\n",
    "                image = Image.fromarray(image)\n",
    "                image.save(tmp_file, format=\"PNG\")\n",
    "                tmp_file_path = tmp_file.name\n",
    "                url = self.client.upload_file(tmp_file_path)\n",
    "        return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageOps\n",
    "import random\n",
    "\n",
    "\n",
    "def draw_mask(mask, draw, random_color=True):\n",
    "    \"\"\"Draws a mask with a specified color on an image.\n",
    "\n",
    "    Args:\n",
    "        mask (np.array): Binary mask as a NumPy array.\n",
    "        draw (ImageDraw.Draw): ImageDraw object to draw on the image.\n",
    "        random_color (bool): Whether to use a random color for the mask.\n",
    "    \"\"\"\n",
    "    if random_color:\n",
    "        color = (\n",
    "            random.randint(0, 255),\n",
    "            random.randint(0, 255),\n",
    "            random.randint(0, 255),\n",
    "            153,\n",
    "        )\n",
    "    else:\n",
    "        color = (30, 144, 255, 153)\n",
    "\n",
    "    nonzero_coords = np.transpose(np.nonzero(mask))\n",
    "    \n",
    "    for coord in nonzero_coords:\n",
    "        draw.point(coord[::-1], fill=color)\n",
    "\n",
    "def visualize(image_pil: Image,\n",
    "              result: Dict,\n",
    "              draw_width: float = 2.0,\n",
    "              return_mask=True,\n",
    "              draw_score=True) -> Image:\n",
    "    \"\"\"Plot bounding boxes and labels on an image.\n",
    "\n",
    "    Args:\n",
    "        image_pil (PIL.Image): The input image as a PIL Image object.\n",
    "        result (Dict[str, Union[torch.Tensor, List[torch.Tensor]]]): The target dictionary containing\n",
    "            the bounding boxes and labels. The keys are:\n",
    "                - boxes (List[int]): A list of bounding boxes in shape (N, 4), [x1, y1, x2, y2] format.\n",
    "                - scores (List[float]): A list of scores for each bounding box. shape (N)\n",
    "                - categorys (List[str]): A list of categorys for each object\n",
    "                - masks (List[PIL.Image]): A list of masks in the format of PIL.Image\n",
    "        draw_score (bool): Draw score on the image. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: The input image with plotted bounding boxes, labels, and masks.\n",
    "    \"\"\"\n",
    "    # Get the bounding boxes and labels from the target dictionary\n",
    "    boxes = result[\"boxes\"]\n",
    "    scores = result[\"scores\"]\n",
    "    categorys = result[\"categorys\"]\n",
    "    masks = result.get(\"masks\", [])\n",
    "\n",
    "    # Find all unique categories and build a cate2color dictionary\n",
    "    cate2color = {}\n",
    "    unique_categorys = set(categorys)\n",
    "    for cate in unique_categorys:\n",
    "        cate2color[cate] = tuple(np.random.randint(0, 255, size=3).tolist())\n",
    "\n",
    "    # Create a PIL ImageDraw object to draw on the input image\n",
    "    if isinstance(image_pil, np.ndarray):\n",
    "        image_pil = Image.fromarray(image_pil)\n",
    "    draw = ImageDraw.Draw(image_pil)\n",
    "    \n",
    "    # Create a new binary mask image with the same size as the input image\n",
    "    mask = Image.new(\"L\", image_pil.size, 0)\n",
    "    # Create a PIL ImageDraw object to draw on the mask image\n",
    "    mask_draw = ImageDraw.Draw(mask)\n",
    "\n",
    "    # Draw boxes, labels, and masks for each box and label in the target dictionary\n",
    "    for box, score, category in zip(boxes, scores, categorys):\n",
    "        # Extract the box coordinates\n",
    "        x0, y0, x1, y1 = box\n",
    "        x0, y0, x1, y1 = int(x0), int(y0), int(x1), int(y1)\n",
    "        color = cate2color[category]\n",
    "\n",
    "        # Draw the box outline on the input image\n",
    "        draw.rectangle([x0, y0, x1, y1], outline=color, width=int(draw_width))\n",
    "\n",
    "        # Draw the label and score on the input image\n",
    "        if draw_score:\n",
    "            text = f\"{category} {score:.2f}\"\n",
    "        else:\n",
    "            text = f\"{category}\"\n",
    "        \n",
    "        font = ImageFont.load_default()\n",
    "        if hasattr(font, \"getbbox\"):\n",
    "            bbox = draw.textbbox((x0, y0), text, font)\n",
    "        else:\n",
    "            w, h = draw.textsize(text, font)\n",
    "            bbox = (x0, y0, w + x0, y0 + h)\n",
    "        draw.rectangle(bbox, fill=color)\n",
    "        draw.text((x0, y0), text, fill=\"white\")\n",
    "\n",
    "    # Draw the mask on the input image if masks are provided\n",
    "    if len(masks) > 0 and return_mask:\n",
    "        size = image_pil.size\n",
    "        mask_image = Image.new(\"RGBA\", size, color=(0, 0, 0, 0))\n",
    "        mask_draw = ImageDraw.Draw(mask_image)\n",
    "        for mask in masks:\n",
    "            mask = np.array(mask)[:, :, -1]\n",
    "            draw_mask(mask, mask_draw)\n",
    "\n",
    "        image_pil = Image.alpha_composite(image_pil.convert(\"RGBA\"), mask_image).convert(\"RGB\")\n",
    "    return image_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "# from gdino import GroundingDINOAPIWrapper, visualize\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Interactive Inference\")\n",
    "    parser.add_argument(\n",
    "        \"--token\",\n",
    "        type=str,\n",
    "        help=\"The token for T-Rex2 API. We are now opening free API access to T-Rex2\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--box_threshold\", type=float, default=0.3, help=\"The threshold for box score\"\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boxes': [[254.161376953125, 151.2242431640625, 317.3817443847656, 267.26177978515625], [327.18585205078125, 273.8308410644531, 360.1203308105469, 303.373291015625], [257.3326721191406, 285.97821044921875, 305.6603088378906, 416.70050048828125], [330.5942077636719, 208.18125915527344, 371.4006652832031, 280.07720947265625], [290.14483642578125, 149.88197326660156, 361.82049560546875, 260.062255859375], [223.63839721679688, 152.44775390625, 287.3518371582031, 266.7746276855469], [360.3450927734375, 272.4895324707031, 462.4224853515625, 322.0088806152344], [514.9003295898438, 267.6614990234375, 593.6388549804688, 308.60931396484375], [465.001953125, 322.6297607421875, 541.7236938476562, 340.9342041015625], [295.7071838378906, 304.67388916015625, 372.47747802734375, 367.7409362792969], [193.13531494140625, 251.0772247314453, 342.9294128417969, 345.8377685546875], [370.5850830078125, 232.21463012695312, 440.8970642089844, 273.5421447753906], [370.3722839355469, 287.18707275390625, 466.7249450683594, 389.8162536621094], [-0.03593730926513672, 307.0261535644531, 318.40087890625, 460.95709228515625]], 'categorys': ['trash bin', 'spoon', 'plastic bottle', 'cup', 'trash bin', 'trash bin', 'plate', 'packet', 'chopstick', 'bowl', 'trash bin', 'foil packet', 'cardboard food box', 'cardboard food box'], 'scores': [0.4603523015975952, 0.7371825575828552, 0.4095976948738098, 0.6511044502258301, 0.5431899428367615, 0.472757488489151, 0.6972837448120117, 0.33335939049720764, 0.3133382797241211, 0.7036380171775818, 0.4562934637069702, 0.4861616790294647, 0.36609646677970886, 0.33612197637557983], 'masks': []}\n"
     ]
    }
   ],
   "source": [
    "image_path = '/Users/niccolofusai/Documents/pi/data/input/image.png'\n",
    "gdino = GroundingDINOAPIWrapper('acb5ee944d3ff954cb5d2c38d1f5cab8')\n",
    "prompts = dict(image=image_path, prompt='cup.bowl.plate.chopstick.plastic bottle.spoon.fork.packet.container.robot gripper.trash bin.foil packet.plastic container. transparent plastic packet.cardboard food container')\n",
    "# prompts = dict(image=image_path, prompt='cup.bowl.plate.chopstick.plastic bottle.spoon.fork.packet.container.robot gripper.trash bin.foil packet.plastic container.cardboard food box')\n",
    "results = gdino.inference(prompts)\n",
    "print(results)\n",
    "# now visualize the results\n",
    "image_pil = Image.open(prompts['image'])\n",
    "image_pil = visualize(image_pil, results)\n",
    "# Convert RGBA to RGB before saving\n",
    "if image_pil.mode == 'RGBA':\n",
    "    image_pil = image_pil.convert('RGB')\n",
    "# dump the image to the disk\n",
    "image_pil.save('/Users/niccolofusai/Documents/pi/data/output/demo_output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['boxes', 'categorys', 'scores', 'masks'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cup',\n",
       " 'trash bin',\n",
       " 'foil packet',\n",
       " 'cardboard food container',\n",
       " 'trash bin',\n",
       " 'chopstick',\n",
       " 'packet',\n",
       " 'cardboard food container',\n",
       " 'trash bin',\n",
       " 'plastic bottle',\n",
       " 'trash bin',\n",
       " ' transparent plastic packet',\n",
       " 'plate',\n",
       " 'bowl',\n",
       " 'spoon']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['categorys']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
